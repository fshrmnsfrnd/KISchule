{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!\"C:\\Program Files\\Python310\\python.exe\" -m pip install langchain>=0.1.17 openai>=1.13.3 langchain_openai>=0.1.6 transformers>=4.40.1 datasets>=2.18.0 accelerate>=0.27.2 sentence-transformers>=2.5.1 duckduckgo-search>=5.2.2 torch\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" \"C:\\Program Files\\Python310\\python.exe\" -m pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaB0B1LdMcPM"
   },
   "source": [
    "## LLM und Tokenizer laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:584\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_name\u001b[39m(device: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:616\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    605\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    617\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:403\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "977271302f104ebdb11c0a2a8183cc93",
      "931c6ca8360a4e79924399f017f5522d",
      "2ff276f9bbab440bb036c1109c023582",
      "6d5243b8997d4f64af62900cb19489d0",
      "680d3647069b45c0b4353548ac52ef37",
      "0512bf845dda462395f58c06dfb0733d",
      "26985bad36884566a7bd4ba6f1037e80",
      "e174502c4dfe4740922264d67a9a74b5",
      "9da5552b33c1418d9e0190ec66f19c9d",
      "33acfbdb950545a6a67a9b39be02e30b",
      "c6d9399532c14ce58189b9d038e4cfa4"
     ]
    },
    "executionInfo": {
     "elapsed": 58517,
     "status": "ok",
     "timestamp": 1715083822638,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "mNkbw28oMeAM",
    "outputId": "c0b97b59-180f-427f-8d49-398cb1b39c40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'is_floating_point'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, pipeline\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-mini-4k-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#\"./models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85\",\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#\"./models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85\",)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    605\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:288\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:5097\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   5092\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m load_gguf_checkpoint(checkpoint_files[\u001b[38;5;241m0\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_to_load\u001b[38;5;241m=\u001b[39mdummy_model)[\n\u001b[0;32m   5093\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5094\u001b[0m         ]\n\u001b[0;32m   5096\u001b[0m     \u001b[38;5;66;03m# Find the correct dtype based on current state\u001b[39;00m\n\u001b[1;32m-> 5097\u001b[0m     config, dtype, dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5098\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\n\u001b[0;32m   5099\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5101\u001b[0m config\u001b[38;5;241m.\u001b[39mname_or_path \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m   5102\u001b[0m model_init_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_init_context(is_quantized, _is_ds_init_called)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:1395\u001b[0m, in \u001b[0;36m_get_dtype\u001b[1;34m(cls, dtype, checkpoint_files, config, sharded_metadata, state_dict, weights_only)\u001b[0m\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1391\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dtype` can be one of: `torch.dtype`, `\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`, a string of a valid `torch.dtype` or a `dict` with valid `dtype` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1392\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor each sub-config in composite configs, but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1393\u001b[0m         )\n\u001b[1;32m-> 1395\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_default_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# set fp32 as the default dtype for BC\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:2461\u001b[0m, in \u001b[0;36mPreTrainedModel._set_default_dtype\u001b[1;34m(cls, dtype)\u001b[0m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_default_dtype\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dtype: torch\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[0;32m   2446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;124;03m    Change the default dtype and return the previous one. This is needed when wanting to instantiate the model\u001b[39;00m\n\u001b[0;32m   2448\u001b[0m \u001b[38;5;124;03m    under specific dtype.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;124;03m    `torch.int64` is passed. So if a non-float `dtype` is passed this functions will throw an exception.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m:\n\u001b[0;32m   2462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2463\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model under dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m since it is not a floating point dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2464\u001b[0m         )\n\u001b[0;32m   2466\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstantiating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model under default dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'is_floating_point'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    #\"./models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85\",\n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")#\"./models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85\",)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ol5aCUfM9bjM"
   },
   "source": [
    "# Übung\n",
    "## Aufgabe 1:\n",
    "Erzeugen Sie einen one_shot_prompt bei dem Sie das Wort \"Gedankenexperiment\" als user und assistent erklären. Anschließend machen Sie ein Beispiel zum  Wort \"Brezn\" und lassen Sie sich darauf hin ein Satz mit Brezn bilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1715085868022,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "Ne92BtrXU8k8",
    "outputId": "ce08f1ae-8fb4-4c39-cb18-8d975f5ced31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Ein Gedankenexperiment ist wenn man etwas in Gedanken durchspielt<|end|>\n",
      "<|user|>\n",
      "Ein Beispiel für ein Gedankenexperiment mit Brezn ist:<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "one_shot_prompt = [\n",
    "{\"role\":\"user\", \"content\": \"Ein Gedankenexperiment ist wenn man etwas in Gedanken durchspielt\"},\n",
    "{\"role\": \"assistent\", \"content\": \"Ich mache ein Gedankenexperiment, wieviel kilonewton der Knoten einer Brezn halten kann.\"},\n",
    "{\"role\":\"user\", \"content\": \"Ein Beispiel für ein Gedankenexperiment mit Brezn ist:\"},\n",
    "]\n",
    "print(tokenizer.apply_chat_template(one_shot_prompt, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3555,
     "status": "ok",
     "timestamp": 1715085873636,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "Ox3LeHW5JfaD",
    "outputId": "e803e67e-b0c2-4823-d1c9-d1f9bba1642b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ein Gedankenexperiment mit Brot könnte lauten: \"Stellen Sie sich vor, Sie haben eine Brotscheibe, die aus einem unbekannten, neuen Kulturen hergestellten Getreide besteht. Sie möchten herausfinden, ob diese Brotart gesünder ist als die herkömmliche Weißbrotart. Sie entscheiden sich, eine Studie durchzuführen, in der Sie zwei Gruppen von Menschen haben. Eine Gruppe isst täglich die neue Brotart, während die andere Gruppe weiterhin Weißbrot isst. Nach einem Monat messen Sie die Blutzuckerspiegel und den Cholesterinspiegel beider Gruppen. Wenn die Gruppe, die die neue Brotart isst, niedrigere Werte aufweist, könnte dies darauf hindeuten, dass die neue Brotart gesünder ist.\"\n"
     ]
    }
   ],
   "source": [
    "# Erzeugung des Outputs\n",
    "outputs = pipe(one_shot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cugB9temhHJ0"
   },
   "source": [
    "## Aufgabe 2: Chain Prompting\n",
    "Erzeugen Sie mit Hilfe mehrere Prompts einen Namen und einen Slogan für einen Brezn Verkaufsautomaten.\n",
    "Nutzen Sie anschließend das Ergebnis um hierfür eine Produktbeschreibung in drei Sätzen zu generieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3336,
     "status": "ok",
     "timestamp": 1715086284771,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "VXYuFn9eG2t4",
    "outputId": "3f96c196-8d37-44ca-fad5-94ddcbe8fc57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name: \"Brez'nator\"\n",
      "\n",
      "Slogan: \"Brez'nator – Die Brez'n-Welt, wo jeder Brezen ein Geschenk ist!\"\n"
     ]
    }
   ],
   "source": [
    "product_prompt = [\n",
    "{\"role\": \"user\", \"content\": \"Erzeuge einen Namen und einen Slogan für einen Brezen Verkaufsautomaten\"}\n",
    "]\n",
    "outputs = pipe(product_prompt)\n",
    "product_description = outputs[0][\"generated_text\"]\n",
    "print(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8805,
     "status": "ok",
     "timestamp": 1715086322608,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "fNYi3eDRG9Sk",
    "outputId": "0e1f5a80-27a4-42ef-b514-36e54dea708c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Der Brez'nator ist nicht nur ein Snack, sondern eine Erfahrung, die jeden Tag neu enthüllt. Mit seinen vielfältigen Geschmacksrichtungen und der innovativen Brez'n-Welt-Konzeption bietet er eine Vielfalt an Geschenken für jeden Morgen. Er ist der perfekte Begleiter für jede Aktivität, sei es ein entspannter Morgen oder ein dynamischer Tag.\n"
     ]
    }
   ],
   "source": [
    "sales_prompt = [\n",
    "{\"role\": \"user\", \"content\": f\"Generiere eine Produktbeschreibung in 3 Sätzen zu folgendem Produkt: '{product_description}'\"}\n",
    "]\n",
    "outputs = pipe(sales_prompt)\n",
    "sales_pitch = outputs[0][\"generated_text\"]\n",
    "print(sales_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jVOOib72Z0P"
   },
   "source": [
    "## Aufgabe3: Zero-shot Chain-of-Thought\n",
    "Folgende Angabe ist gegeben:\n",
    "\n",
    "Ein Metzger verkauft Weißwürste. Er hat 3 Pfund Weißwürste, die pro Pfund 4,50 € kosten und 240g Butter pro Pfund enthalten. Pro Weißwurst sind 12g Schweinefleisch verarbeitet. 1 Pfund (ca. 454g) ist ein 10-teiliges Paket. Eine Weißwurst wiegt ca. 50g. Ein Kunde möchte 10 Weißwürste kaufen, aber er hat nur 15 € dabei und möchte noch ein 250g Päckchen Butter dazu kaufen, das 1,80 € kostet. \n",
    "\n",
    "Nutzen Sie das LLM um eine oder mehrere der folgenden Fragen zu lösen. Funktioniert die Lösung mit oder ohne aufzeichnung der Schritte besser?\n",
    "\n",
    "1. Wie viele Weißwürste sind in den 3 Pfund, die der Metzger hat?\n",
    "2. Wie viel Gramm Fleisch sind in einer Weißwurst enthalten?\n",
    "3. Wie viel wiegen die 10 Weißwürste, die der Kunde kaufen möchte, und wie viel kostet das?\n",
    "4. Kauft der Kunde genug Weißwürste für ein Pfund, und ist es genug Fleisch für eine Mahlzeit für ihn und seine Familie?\n",
    "5. Wie viel Geld bekommt der Metzger, wenn der Kunde die Weißwürste und die Butter bezahlt?\n",
    "6. Was ist die Gesamtzahl an benötigten Weißwürsten für einen Einkauf von 2 Paketen à 1 Pfund plus Butter für ein 500g Paket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5802,
     "status": "ok",
     "timestamp": 1715086681529,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "iyHWAk2XKKGt",
    "outputId": "c6baf07b-5b72-4997-8499-aa8015303abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 Pfund sind 10 Weißwürste, 3 * 10 = 30. Also sind 3 Pfund gleich 30 Weißwürste. 1 Weißwurst enthält 12g Schweinefleisch. Also sind 30 Weißwürste 30 * 12g = 360g Fleisch.\n"
     ]
    }
   ],
   "source": [
    "Zeroshot_prompt=[\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Ein Metzger verkauft Weißwürste. Er hat 3 Pfund Weißwürste, die pro Pfund 4,50 € kosten und 240g Butter pro Pfund enthalten. Pro Weißwurst sind 12g Schweinefleisch verarbeitet. 1 Pfund (ca. 454g) ist ein 10-teiliges Paket. Eine Weißwurst wiegt ca. 50g. Ein Kunde möchte 10 Weißwürste kaufen, aber er hat nur 15 € dabei und möchte noch ein 250g Päckchen Butter dazu kaufen, das 1,80 € kostet. Wie viele Weißwürste sind in den 3 Pfund, die der Metzger hat? Denke Schritt für Schritt.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"1 Pfund sind 10 Weißwürste, 3 * 10 = 30. Also sind 3 Pfund gleich 30 Weißwürste\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Ein Metzger verkauft Weißwürste. Er hat 3 Pfund Weißwürste, die pro Pfund 4,50 € kosten und 240g Butter pro Pfund enthalten. Pro Weißwurst sind 12g Schweinefleisch verarbeitet. 1 Pfund (ca. 454g) ist ein 10-teiliges Paket. Eine Weißwurst wiegt ca. 50g. Ein Kunde möchte 10 Weißwürste kaufen, aber er hat nur 15 € dabei und möchte noch ein 250g Päckchen Butter dazu kaufen, das 1,80 € kostet. Wie viel Gramm Fleisch sind in einer Weißwurst enthalten? Denke Schritt für Schritt.\"\n",
    "    },\n",
    "]\n",
    "outputs = pipe(Zeroshot_prompt)\n",
    "Zeroshot_pitch = outputs[0][\"generated_text\"]\n",
    "print(Zeroshot_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3-bMVLT2ehH"
   },
   "source": [
    "## Aufgabe 4: Tree-of-Thought: \n",
    "Erstellen Sie einen Prompt der folgende Bedingungen erfüllt:\n",
    "- 3 Experten diskutieren\n",
    "- Jeder Experte denkt Schrittweise denken.\n",
    "- Die Experten teilen und vergleichen ihre Ergebnisse bevor sie zum nächsten Schritt wechseln\n",
    "- Sobald ein Experte falsch liegt meldet, dieser sein falsches Ergebnis und scheidet anschließend aus.\n",
    "- Die Gruppe soll folgende Frage beantworten:\n",
    "  Wenn Sie 26 Brezn besitzen und 20 Brezn für das Mittagessen verbrauchen und 6 Brezn neu kaufen,\"\n",
    "    \" wie viele Brezn haben Sie dann\n",
    "- Die Experten sollen Ihr die Ergebnisse diskutieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZJo-4NBI1V-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyCw3A5GZ61D"
   },
   "source": [
    "## Aufgabe 5: Output Verification\n",
    "Generiere ein Brezn Rezept in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24562,
     "status": "ok",
     "timestamp": 1715087067979,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "NBc_HuJQY8sh",
    "outputId": "818a31a8-7dd6-4d70-feec-5db827b491d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [{'name':'Brezen'}, {'Zutaten': 'Weizenmehl, Salz, Hefe, Wasser, Olivenöl'}, {'Zubereitung':'Mehl mit Salz vermischen, Hefe mit Wasser auftragen, alles zu einem Teig verarbeiten, den Teig auf einem Teiglappen legen, mit Olivenöl bestreichen, mit einem Brezelstylzirkel ausrollen, die Brezen mit einem Brezelstylzirkel ausschneiden, die Brezen auf einem Backblech auslegen, 20 Minuten bei 220°C backen'}, {'Garantie':'Genießerisches, knuspriges Brot'}\n"
     ]
    }
   ],
   "source": [
    "product_prompt = [\n",
    "{\"role\": \"user\", \"content\": \"Erzeuge ein Brot Rezept im JSON Format\"},\n",
    "{\"role\": \"assistant\", \"content\": \"[{'name':'Brot'}, {'Zutaten': 'Mehl', 'Wasser'}], {'Zubereitung':'Alles verrühren, dann backen bis es braun ist'}\"},\n",
    "{\"role\": \"user\", \"content\": \"Erzeuge ein Brezen Rezept im JSON Format\"},\n",
    "]\n",
    "outputs = pipe(product_prompt)\n",
    "product_description = outputs[0][\"generated_text\"]\n",
    "print(product_description)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMRJzDTVTlBntcudlyKW5VZ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
